{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEIZ_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAecqQvaPA3U"
      },
      "outputs": [],
      "source": [
        "!pip install -q snscrape==0.3.4\n",
        "#!pip install lmfit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import cumsum\n",
        "from sklearn import metrics \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from scipy import integrate, optimize\n",
        "from numpy import linalg as la\n",
        "from datetime import date, datetime, timedelta\n",
        "from IPython import display\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "metadata": {
        "id": "82kwzEDcPQPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "BwZQ0H0HPmoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_tweets(search_term, start_date, end_date):\n",
        "  os.system(f\"snscrape --since {start_date} twitter-search '{search_term} until:{end_date}' > result-tweets-{start_date}-{end_date}.txt\")\n",
        "  if os.stat(f\"result-tweets-{start_date}-{end_date}.txt\").st_size == 0:\n",
        "    counter = 0\n",
        "  else:\n",
        "    df = pd.read_csv(f\"result-tweets-{start_date}-{end_date}.txt\", names=['link'])\n",
        "    total_tweets = df.size\n",
        "\n",
        "  return total_tweets, df\n",
        "\n",
        "def get_cumulative_tweets(arr):\n",
        "  cumulative_tweets = cumsum(arr)\n",
        "  return cumulative_tweets\n",
        "\n",
        "def generate_dataset(search_term, total_days):\n",
        "\n",
        "  # # # # # # # # \n",
        "  # Generic code to specify an arbitary time window in (today - total_days, today)\n",
        "  # # # # # # # # \n",
        "  #\n",
        "  # dates = []\n",
        "  # today_date = date.today()\n",
        "  # start_date = today_date - timedelta(days = total_days) \n",
        "\n",
        "  # for i in range(total_days):\n",
        "  #   curr_date = today_date - timedelta(days = i)\n",
        "  #   dates.append(curr_date)\n",
        "\n",
        "  # dates.append(start_date)\n",
        "\n",
        "  # dates.reverse()\n",
        "  # for i in range(len(dates)):\n",
        "  #   dates[i] = dates[i].strftime(\"%Y-%m-%d\")\n",
        "  #\n",
        "  # # # # # # # # \n",
        "\n",
        "  # To maintain consistent results reproduction by TAs,\n",
        "  # we are fixing the data collection window to return\n",
        "  # consistent data used for modeling. We use a start\n",
        "  # date of 2022-2-21 and collect tweets till 2022-04-28\n",
        "\n",
        "  dates = []\n",
        "  total_days = 66\n",
        "  start_date = date(2022, 4, 28)\n",
        "\n",
        "  for i in range(total_days):\n",
        "    curr_date = start_date - timedelta(days = i)\n",
        "    dates.append(curr_date)\n",
        "\n",
        "  dates.append(start_date-timedelta(days=total_days))\n",
        "\n",
        "  dates.reverse()\n",
        "  for i in range(len(dates)):\n",
        "    dates[i] = dates[i].strftime(\"%Y-%m-%d\")\n",
        "\n",
        "\n",
        "  dfs = []\n",
        "  total_tweets = []\n",
        "  for i in range(1,len(dates)):\n",
        "    tweets, df = get_total_tweets(search_term, dates[i-1], dates[i])\n",
        "    total_tweets.append(tweets)\n",
        "    dfs.append(df)\n",
        "    print(\"Tweet scraping from day\",i,\"done\")\n",
        "  \n",
        "  return total_tweets, dfs"
      ],
      "metadata": {
        "id": "WqhG8yOXPWco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_days = 66 \n",
        "search_term = '#IStandWithPutin'\n",
        "total_tweets, dfs = generate_dataset(search_term, total_days)"
      ],
      "metadata": {
        "id": "L_ZMaZ3wxZ-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_tweets"
      ],
      "metadata": {
        "id": "LIOaDDXBU9ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cumulative_tweets = get_cumulative_tweets(total_tweets)\n",
        "cumulative_tweets"
      ],
      "metadata": {
        "id": "4yuX3KB4Vi2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "ZJDPk4MAKRoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seiz(y, t, beta, b, p, l, rho, eps):\n",
        "  \"\"\"\n",
        "  dS - Rate of change of susceptible users with time\n",
        "  dE - Rate of change of exposed users with time\n",
        "  dI - Rate of change of infected users with time\n",
        "  dZ - Rate of change of skeptics users with time\n",
        "  \"\"\"\n",
        "  dS = -beta*y[0]*(y[2]/N) - b*y[0]*(y[3]/N)\n",
        "  dE = (1-p)*beta*y[0]*(y[2]/N) + (1-l)*b*y[0]*(y[3]/N) - rho*y[1]*(y[2]/N) - eps*y[1]\n",
        "  dI = p*beta*y[0]*(y[2]/N) + rho*y[1]*(y[2]/N) + eps*y[1]\n",
        "  dZ = l*b*y[0]*(y[3]/N)\n",
        "\n",
        "  return dS, dE, dI, dZ\n",
        "\n",
        "def fit_seiz(t, beta, b, p, l, rho, eps):\n",
        "  return integrate.odeint(seiz, (ICs), t, args=(beta, b, p, l, rho, eps))[:,1]\n",
        "\n",
        "def get_params(f, xdata, ydata,bounds=True):\n",
        "  if bounds == True:                                                \n",
        "    return optimize.curve_fit(fit_seiz, xdata, ydata, \n",
        "        bounds=([1,1,0,0,10e-05,0], [np.inf, np.inf, 1, 1, 10e-02, 1]))\n",
        "  else:\n",
        "    return optimize.curve_fit(fit_seiz, xdata, ydata)\n",
        "\n",
        "def plot_lsq(ICs, xdata, ydata):\n",
        "  popt, pcov = get_params(fit_seiz, xdata, ydata)\n",
        "  fitted = fit_seiz(xdata, *popt)\n",
        "  fig = plt.figure(figsize=(4,3))\n",
        "  plt.plot(xdata, ydata, 'o')\n",
        "  plt.plot(xdata, fitted)\n",
        "  plt.legend(['Truth', 'Fitted'], loc = 'lower right')\n",
        "  plt.xlabel(\"Days\", fontsize=15)\n",
        "  plt.ylabel(\"Cumulative Tweets\", fontsize=15)\n",
        "  r2_sc = metrics.r2_score(ydata, fitted)\n",
        "  print(\"R2_score=\", r2_sc)\n",
        "  return plt\n",
        "\n",
        "def model(x, t):\n",
        "\n",
        "  \"\"\"\n",
        "  SEIZ ODE model\n",
        "  \"\"\"\n",
        "\n",
        "  beta = popt[0]\n",
        "  b = popt[1]\n",
        "  p = popt[2]\n",
        "  l = popt[3]\n",
        "  rho = popt[4]\n",
        "  eps = popt[5]\n",
        "\n",
        "  S = x[0]\n",
        "  E = x[1]\n",
        "  I = x[2]\n",
        "  Z = x[3]\n",
        "\n",
        "  dSdt = -beta*S*(I/N) - b*S*(Z/N)\n",
        "  dEdt = (1-p)*beta*S*(I/N) + (1-l)*b*S*(Z/N) - rho*E*(I/N) - eps*E\n",
        "  dIdt = p*beta*S*(I/N) + rho*E*(I/N) + eps*E\n",
        "  dZdt = l*b*S*(Z/N)\n",
        "\n",
        "  return [dSdt, dEdt, dIdt, dZdt]\n",
        "\n",
        "def plot_seiz(ICs, xdata):\n",
        "  \"\"\"\n",
        "  ICs: initial conditions for states\n",
        "  xdata: time data\n",
        "  \"\"\"\n",
        "  sol = integrate.odeint(model,ICs,xdata)\n",
        "  fig = plt.figure(figsize=(4,3))\n",
        "  plt.plot(xdata,sol)\n",
        "  plt.legend(['S','E','I','Z'])\n",
        "  plt.xlabel(\"Days\", fontsize=15)\n",
        "  plt.ylabel(\"Cumulative Tweets\", fontsize=15)\n",
        "  return plt\n",
        "\n",
        "def plot_animation(sol):\n",
        "\n",
        "  \"\"\"\n",
        "  sol: ODE solution obtained from integrate.odeint or simulation\n",
        "  \"\"\"\n",
        "\n",
        "  fig = plt.figure(figsize=(8,6))\n",
        "  #ax = plt.axes(xlim=(0, 50), ylim=(0,sol.max()+(0.1*sol.max())))\n",
        "  ax = plt.axes(xlim=(0, sol.shape[0]), ylim=(0,sol.max()+(0.1*sol.max())))\n",
        "  plt.xlabel(\"Days\", fontsize=15)\n",
        "  plt.ylabel(\"Cumulative Tweets\", fontsize=15)\n",
        "  lines = [plt.plot([], [])[0] for _ in range(4)] \n",
        "  patches = lines  \n",
        "\n",
        "  def init():\n",
        "      for line in lines:\n",
        "          line.set_data([], [])\n",
        "\n",
        "      return patches \n",
        "\n",
        "  def animate(i):\n",
        "      for j,line in enumerate(lines):\n",
        "          line.set_data(xdata[:i], sol[:i,j])\n",
        "      plt.legend(['S','E','I','Z'])\n",
        "      return patches\n",
        "\n",
        "  anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                                frames=100, interval=50, blit=True)\n",
        "  video = anim.to_html5_video()\n",
        "  html = display.HTML(video)\n",
        "  return display.display(html)"
      ],
      "metadata": {
        "id": "SSxAADj6Pko9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Params Fit"
      ],
      "metadata": {
        "id": "NiK1MkN4PjAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### Cached values for easy simulation to avoid spending time in scraping. Uncomment values and run the code below for results\n",
        "# total_days = 65\n",
        "# cumulative_tweets = np.array([ 29,    35,   182,   401,   569,   765,  1119,  1466, 14788,\n",
        "#        30574, 33275, 34920, 36236, 37187, 37866, 38367, 38816, 39181,\n",
        "#        39485, 39758, 40024, 40317, 40646, 40951, 41211, 41450, 41679,\n",
        "#        41868, 42077, 42234, 42416, 42550, 42742, 42884, 43002, 43105,\n",
        "#        43241, 43407, 43540, 43657, 43798, 43907, 44031, 44109, 44200,\n",
        "#        44273, 44368, 44458, 44535, 44621, 44697, 44751, 44817, 44875,\n",
        "#        44946, 45052, 45129, 45190, 45265, 45322, 45402, 45485, 45551,\n",
        "#        45607, 45661])"
      ],
      "metadata": {
        "id": "LMEYFl6AgMh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xdata = np.array([x for x in range(total_days)])\n",
        "ydata = cumulative_tweets  # first 5 days tweets are low\n",
        "\n",
        "ydata = np.array(ydata, dtype=float)\n",
        "xdata = np.array(xdata, dtype=float)\n",
        "\n",
        "# initial conditions\n",
        "N = 100000\n",
        "I0 = ydata[0]\n",
        "E0 = 100\n",
        "Z0 = 100\n",
        "S0 = N - I0 - E0 - Z0\n",
        "R0 = 0\n",
        "ICs = [S0, I0, E0, Z0]\n",
        "\n",
        "popt, pcov = get_params(fit_seiz, xdata, ydata, bounds = False)\n",
        "popt, pcov = get_params(fit_seiz, xdata, ydata)"
      ],
      "metadata": {
        "id": "Hlz9nceMCscb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_lsq(ICs, xdata, ydata)"
      ],
      "metadata": {
        "id": "YPsaH0RWBduz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_seiz(ICs,xdata)"
      ],
      "metadata": {
        "id": "v0B5BK-pKk6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution Animation"
      ],
      "metadata": {
        "id": "mNGr_pGKQRi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sol = integrate.odeint(model,ICs,xdata)\n",
        "plot_animation(sol)"
      ],
      "metadata": {
        "id": "Y3HWzPOQU3D7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}